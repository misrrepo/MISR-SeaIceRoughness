{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "581c2f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n*********************************************\\nthis code produces cloud-mask binary data products for all MISR image blocks that we used in SIR prediction.\\n*********************************************\\n\\nsteps:\\nload the model and use the trained model for prediction.\\nproduce cloud-mask binary files.\\nthen we use these cloud-mask binary files in the SIR.c code and predict the SIR \\nand check if SIR predictions have improved\\n\\ninputs: red-band from 9 cameras\\n\\noutput: predicted cloud-mask for each block\\n\\nto-do:\\ncheck file type of cloudmask inside SIR code; what format does input cloudmask file have in that code?\\nfor-loop for the whole code\\nmake a list of POB form all available toa-refls to keep count \\n\\nok- extract POB fro toa-refl\\nok- fillvalue from previous MISR cloudmasks?\\nok- skip a pixel if there is [-1]?\\nok- update the the predicted categorical list with fillvalue using indexing and assignment\\n***********************\\n? check 0,1 output in cloudmask output file; shoudl be binary, not float? \\n>>> output cloudmask format is now [int8] [8 bits== range[-128,127]]; -2 is the fillvalue\\n\\n? check format of this cloudmask as input file to the next code (atmmodel?) dtype= uint8? or int8?\\n\\n\\nthen:\\n? run for a cloudy image and compare with baseline==visual conformation\\n\\n\\nfinally- I need a code to read a cloudmask binary file and update the traning dataset for a specific cloudy block and then update the specific column for future comparison between my model and MISR cloudmasks\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "*********************************************\n",
    "this code produces cloud-mask binary data products for all MISR image blocks that we used in SIR prediction.\n",
    "*********************************************\n",
    "\n",
    "steps:\n",
    "load the model and use the trained model for prediction.\n",
    "produce cloud-mask binary files.\n",
    "then we use these cloud-mask binary files in the SIR.c code and predict the SIR \n",
    "and check if SIR predictions have improved\n",
    "\n",
    "inputs: red-band from 9 cameras\n",
    "\n",
    "output: predicted cloud-mask for each block\n",
    "\n",
    "to-do:\n",
    "check file type of cloudmask inside SIR code; what format does input cloudmask file have in that code?\n",
    "for-loop for the whole code\n",
    "make a list of POB form all available toa-refls to keep count \n",
    "\n",
    "ok- extract POB fro toa-refl\n",
    "ok- fillvalue from previous MISR cloudmasks?\n",
    "ok- skip a pixel if there is [-1]?\n",
    "ok- update the the predicted categorical list with fillvalue using indexing and assignment\n",
    "***********************\n",
    "? check 0,1 output in cloudmask output file; shoudl be binary, not float? \n",
    ">>> output cloudmask format is now [int8] [8 bits== range[-128,127]]; -2 is the fillvalue\n",
    "\n",
    "? check format of this cloudmask as input file to the next code (atmmodel?) dtype= uint8? or int8?\n",
    "\n",
    "\n",
    "then:\n",
    "? run for a cloudy image and compare with baseline==visual conformation\n",
    "\n",
    "\n",
    "finally- I need a code to read a cloudmask binary file and update the traning dataset for a specific cloudy block and then update the specific column for future comparison between my model and MISR cloudmasks\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a44c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "import MisrToolkit as Mtk\n",
    "from MisrToolkit import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41275d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input files for the model\n",
    "# inputs: 9 TOA reflectance red bands- order is important\n",
    "\n",
    "toa_refl_dir = \"/Users/ehsanmos/MLP_dataset/cloudmask_lab/prediction_test_cloudmask/test_cloudmask_p167_b10_july\"\n",
    "\n",
    "output_dir = toa_refl_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67e0a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to model & directory\n",
    "\n",
    "model_name = \"model_July_loss0.25_acc0.91.h5\"\n",
    "model_dir = \"/Users/ehsanmos/MLP_dataset/cloudmask_lab/training_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f9d1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                640       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 2,786\n",
      "Trainable params: 2,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load the model for april/july\n",
    "\n",
    "model_fp = os.path.join(model_dir, model_name) \n",
    "# load model\n",
    "mlp_model_best = load_model(model_fp)\n",
    "# summarize model.\n",
    "mlp_model_best.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b36654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check toa-refl directory available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122d373b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# get a list of toa_refl files\n",
    "\n",
    "toa_refl_filePattern = \"toa_refl_P*.dat\"\n",
    "\n",
    "toa_refl_list = glob(os.path.join(toa_refl_dir, toa_refl_filePattern))\n",
    "print(len(toa_refl_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd3fc59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ehsanmos/MLP_dataset/cloudmask_lab/prediction_test_cloudmask/test_cloudmask_p167_b10_july/toa_refl_P167_O088219_B010_da_red.dat',\n",
       " '/Users/ehsanmos/MLP_dataset/cloudmask_lab/prediction_test_cloudmask/test_cloudmask_p167_b10_july/toa_refl_P167_O088219_B010_ba_red.dat',\n",
       " '/Users/ehsanmos/MLP_dataset/cloudmask_lab/prediction_test_cloudmask/test_cloudmask_p167_b10_july/toa_refl_P167_O088219_B010_ca_red.dat',\n",
       " '/Users/ehsanmos/MLP_dataset/cloudmask_lab/prediction_test_cloudmask/test_cloudmask_p167_b10_july/toa_refl_P167_O088219_B010_an_red.dat',\n",
       " '/Users/ehsanmos/MLP_dataset/cloudmask_lab/prediction_test_cloudmask/test_cloudmask_p167_b10_july/toa_refl_P167_O088219_B010_af_red.dat',\n",
       " '/Users/ehsanmos/MLP_dataset/cloudmask_lab/prediction_test_cloudmask/test_cloudmask_p167_b10_july/toa_refl_P167_O088219_B010_df_red.dat',\n",
       " '/Users/ehsanmos/MLP_dataset/cloudmask_lab/prediction_test_cloudmask/test_cloudmask_p167_b10_july/toa_refl_P167_O088219_B010_bf_red.dat',\n",
       " '/Users/ehsanmos/MLP_dataset/cloudmask_lab/prediction_test_cloudmask/test_cloudmask_p167_b10_july/toa_refl_P167_O088219_B010_cf_red.dat',\n",
       " '/Users/ehsanmos/MLP_dataset/cloudmask_lab/prediction_test_cloudmask/test_cloudmask_p167_b10_july/toa_refl_P167_O088219_B010_aa_red.dat']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toa_refl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "695e1e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-o-b was added to list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['P167_O088219_B010']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a list of POB form all available toa-refls to keep count of the number fo toa-refl files available\n",
    "\n",
    "p_o_b_process_list = []\n",
    "\n",
    "for toa_refl in toa_refl_list:\n",
    "    #print(toa_refl)\n",
    "    p_o_b_list = toa_refl.split('/')[-1].split('_')[2:5]\n",
    "#     print(p_o_b_list)\n",
    "    #print(file_name.split('_')[2:4])\n",
    "#     p_o_list = file_name.split('_')[2:4]\n",
    "    p_o_b = p_o_b_list[0]+\"_\"+p_o_b_list[1]+\"_\"+p_o_b_list[2]\n",
    "#     print(p_o_b)\n",
    "\n",
    "    if p_o_b in p_o_b_process_list:\n",
    "        continue\n",
    "    else:\n",
    "        p_o_b_process_list.append(p_o_b)\n",
    "        print(\"p-o-b was added to list\")\n",
    "        \n",
    "        \n",
    "p_o_b_process_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17637cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define and open 9 cameras in order\n",
    "## based on order of input to MLP- based on order of cameras in training dataset\n",
    "# later select toa-refls based on POB from inventory; then in the for-loop\n",
    "\n",
    "# for-loop here for every POB in the p_o_b_process_list, open each 9 files together and process them\n",
    "\n",
    "# for POB in p_o_b_process_list\"\n",
    "POB = p_o_b_process_list[0] # get the first one on the list manually\n",
    "\n",
    "\n",
    "# cf_r = \"toa_refl_\"+p_o+\"_B0\"+toa_block+\"_cf_red.dat\"\n",
    "da_r = 'toa_refl_'+POB+'_da_red.dat'\n",
    "# print(da_r)\n",
    "df_r = 'toa_refl_'+POB+'_df_red.dat'\n",
    "ca_r = 'toa_refl_'+POB+'_ca_red.dat'\n",
    "cf_r = 'toa_refl_'+POB+'_cf_red.dat'\n",
    "ba_r = 'toa_refl_'+POB+'_ba_red.dat'\n",
    "bf_r = 'toa_refl_'+POB+'_bf_red.dat'\n",
    "aa_r = 'toa_refl_'+POB+'_aa_red.dat'\n",
    "af_r = 'toa_refl_'+POB+'_af_red.dat'\n",
    "an_r = 'toa_refl_'+POB+'_an_red.dat'\n",
    "\n",
    "\n",
    "\n",
    "########### open and read toa-refl as np-arr\n",
    "if (os.path.isfile(os.path.join(toa_refl_dir, an_r))==False):\n",
    "    print(\"block not found- continue\")\n",
    "#     continue\n",
    "an_r_arr = np.fromfile(os.path.join(toa_refl_dir, an_r), dtype=np.double)[0:1048576].reshape((512,2048))\n",
    "## check black- continue:\n",
    "if (np.median(an_r_arr) == -1.0):\n",
    "    print(\"image black- continue\")\n",
    "#     continue\n",
    "\n",
    "\n",
    "\n",
    "########### open and read toa-refl as np-arr\n",
    "if (os.path.isfile(os.path.join(toa_refl_dir, aa_r))==False):\n",
    "    print(\"block not found- continue\")\n",
    "#     continue\n",
    "aa_r_arr = np.fromfile(os.path.join(toa_refl_dir, aa_r), dtype=np.double)[0:1048576].reshape((512,2048))\n",
    "## check black- continue:\n",
    "if (np.median(aa_r_arr) == -1.0):\n",
    "    print(\"image black- continue\")\n",
    "#     continue\n",
    "\n",
    "\n",
    "\n",
    "########### open and read toa-refl as np-arr\n",
    "if (os.path.isfile(os.path.join(toa_refl_dir, af_r))==False):\n",
    "    print(\"block not found- continue\")\n",
    "#     continue\n",
    "af_r_arr = np.fromfile(os.path.join(toa_refl_dir, af_r), dtype=np.double)[0:1048576].reshape((512,2048))\n",
    "## check black- continue:\n",
    "if (np.median(af_r_arr) == -1.0):\n",
    "    print(\"image black- continue\")\n",
    "#     continue\n",
    "\n",
    "\n",
    "\n",
    "########### open and read toa-refl as np-arr\n",
    "if (os.path.isfile(os.path.join(toa_refl_dir, ba_r))==False):\n",
    "    print(\"block not found- continue\")\n",
    "#     continue\n",
    "ba_r_arr = np.fromfile(os.path.join(toa_refl_dir, ba_r), dtype=np.double)[0:1048576].reshape((512,2048))\n",
    "## check black- continue:\n",
    "if (np.median(ba_r_arr) == -1.0):\n",
    "    print(\"image black- continue\")\n",
    "#     continue\n",
    "\n",
    "\n",
    "########### open and read toa-refl as np-arr\n",
    "if (os.path.isfile(os.path.join(toa_refl_dir, bf_r))==False):\n",
    "    print(\"block not found- continue\")\n",
    "#     continue\n",
    "bf_r_arr = np.fromfile(os.path.join(toa_refl_dir, bf_r), dtype=np.double)[0:1048576].reshape((512,2048))\n",
    "## check black- continue:\n",
    "if (np.median(bf_r_arr) == -1.0):\n",
    "    print(\"image black- continue\")\n",
    "#     continue\n",
    "\n",
    "\n",
    "\n",
    "########### open and read toa-refl as np-arr\n",
    "if (os.path.isfile(os.path.join(toa_refl_dir, ca_r))==False):\n",
    "    print(\"block not found- continue\")\n",
    "#     continue\n",
    "ca_r_arr = np.fromfile(os.path.join(toa_refl_dir, ca_r), dtype=np.double)[0:1048576].reshape((512,2048))\n",
    "## check black- continue:\n",
    "if (np.median(ca_r_arr) == -1.0):\n",
    "    print(\"image black- continue\")\n",
    "#     continue\n",
    "\n",
    "\n",
    "\n",
    "########### open and read toa-refl as np-arr\n",
    "if (os.path.isfile(os.path.join(toa_refl_dir, cf_r))==False):\n",
    "    print(\"block not found- continue\")\n",
    "#     continue\n",
    "cf_r_arr = np.fromfile(os.path.join(toa_refl_dir, cf_r), dtype=np.double)[0:1048576].reshape((512,2048))\n",
    "## check black- continue:\n",
    "if (np.median(cf_r_arr) == -1.0):\n",
    "    print(\"image black- continue\")\n",
    "#     continue\n",
    "\n",
    "\n",
    "########### open and read toa-refl as np-arr\n",
    "if (os.path.isfile(os.path.join(toa_refl_dir, da_r))==False):\n",
    "    print(\"block not found- continue\")\n",
    "#     continue\n",
    "da_r_arr = np.fromfile(os.path.join(toa_refl_dir, da_r), dtype=np.double)[0:1048576].reshape((512,2048))\n",
    "## check black- continue:\n",
    "if (np.median(da_r_arr) == -1.0):\n",
    "    print(\"image black- continue\")\n",
    "#     continue\n",
    "\n",
    "\n",
    "########### open and read toa-refl as np-arr\n",
    "if (os.path.isfile(os.path.join(toa_refl_dir, df_r))==False):\n",
    "    print(\"block not found- continue\")\n",
    "#     continue\n",
    "df_r_arr = np.fromfile(os.path.join(toa_refl_dir, df_r), dtype=np.double)[0:1048576].reshape((512,2048))\n",
    "## check black- continue:\n",
    "if (np.median(df_r_arr) == -1.0):\n",
    "    print(\"image black- continue\")\n",
    "#     continue\n",
    "\n",
    "\n",
    "# we do not trip blocks, but if there is a bad value/black pixel in the input aarray, we fill that pixel with fillvalue==? from misr cloudmask filvalue\n",
    "\n",
    "\n",
    "\n",
    "# prepare the input array to our model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09448eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 2048)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shapes of all arrays to make sure they all have same shape\n",
    "an_r_arr.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "728c563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# irow = 0\n",
    "# icol = 100  \n",
    "# path = 167\n",
    "# orbit = 88219\n",
    "# block = 10\n",
    "# resolution = 275\n",
    "\n",
    "\n",
    "# an_latlon = bls_to_latlon(path, resolution, block, 100, 1000)\n",
    "# an_latlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c945f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pixel matching ==> does not work; finding pixels based on similar latlons is very hard and not possible based on the matching latlons\n",
    "\n",
    "# # open AN - ok\n",
    "# # find the LS of the first pixel in the image\n",
    "# resolution = 275\n",
    "# an_latlon_list = []\n",
    "\n",
    "# # for irow in range(0, an_r_arr.shape[0]):\n",
    "# #     for icol in range(0, an_r_arr.shape[1]):\n",
    "# #         an = an_r_arr[irow,icol]\n",
    "# #         if (an >= 0): # vaues in array image are TOA reflectance\n",
    "# #             # coolect index info as LS\n",
    "# #             linsam = [irow,icol]\n",
    "# # #             print(linsam)\n",
    "# #             # change LS to location/latlon\n",
    "# # #             bls_to_latlon(path, resolution meters, block, line, sample)\n",
    "    \n",
    "# #             latlon = bls_to_latlon(path, resolution, block, linsam[0], linsam[1])\n",
    "\n",
    "# #             # find this latlon in other 8 cameras\n",
    "# #             #ls_latlon = []\n",
    "# #             linsam_latlon_an.append(linsam, latlon, an)\n",
    "\n",
    "# irow = 100\n",
    "# icol = 800  \n",
    "# path = 167\n",
    "# orbit = 88219\n",
    "# block = 10\n",
    "# linsam = [irow, icol]\n",
    "\n",
    "# an = an_r_arr[irow, icol]\n",
    "# # print(an)\n",
    "# if (an >= 0): # vaues in array image are TOA reflectance\n",
    "#     # coolect index info as LS\n",
    "# #     linsam = [irow,icol]\n",
    "# #             print(linsam)\n",
    "#     # change LS to location/latlon\n",
    "\n",
    "#     an_latlon = bls_to_latlon(path, resolution, block, linsam[0], linsam[1])\n",
    "# #     print(an_latlon)\n",
    "#     # change tuple to int seperately\n",
    "#     an_lat = round(an_latlon[0], 4)\n",
    "#     an_lon = round(an_latlon[1], 4)\n",
    "#     print(an_lat)\n",
    "#     # find this latlon in other 8 cameras\n",
    "# #     an_latlon_list.append(list(an_latlon + (an,))) # how to add 2 tuples to a list\n",
    "#     an_latlon_list.append([an_lat, an_lon, round(an, 6)]) # how to add 2 tuples to a list\n",
    "\n",
    "    \n",
    "# an_latlon_list         \n",
    "# #####################   \n",
    "# # da_latlon_list = []\n",
    "# # for ii in range(512):\n",
    "# #     for jj in range(2048):\n",
    "# #         da = da_r_arr[ii,jj]\n",
    "# #         if (da>=0):\n",
    "# #             # also we need latlon for that pixel\n",
    "# #             da_latlon = bls_to_latlon(path, resolution, block, ii, jj)\n",
    "# #             da_latlon_list.append(da_latlon, da)\n",
    "            \n",
    "            \n",
    "#             # \n",
    "\n",
    "# #####################   \n",
    "# # now match an-latlon with da-latlon and find the da\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #####################               \n",
    "# # # do this for all other 8 cameras\n",
    "# # # find LS from latlons\n",
    "# # for i in ls_latlon_an:\n",
    "# #     x1 = ls_latlon_an[4] # ls_latlon_an should be a list w/5 elements: [l,s,lat,lon,an]\n",
    "# #     an_latlon = ls_latlon_an[2:4]\n",
    "#     # find this latlon in ls_latlon_aa and its corresponding aa and assign it to x2 \n",
    "#     # find this latlon in ls_latlon_af and its corresponding af and assign it to x3 \n",
    "#     # find this latlon in ls_latlon_bf and its corresponding bf and assign it to x4 \n",
    "\n",
    "#     # later make this a lookup table?\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             # from latlon on AN, we find pixel values in other 8 cameras/arrays by matching latlon->LS:\n",
    "#             # latlon -> different LS in each block -> find pixel value + add to lsit \n",
    "#             # convert LS to latlon for each camera\n",
    "#             # match latlon AN with latlon in 8 other cameras and find corresponding LS pixel value for that latlon in 8 cameras\n",
    "            \n",
    "            \n",
    "            \n",
    "#             # use latlon to find LS in other images\n",
    "            \n",
    "#             # collect values of LS in other 8 cameras in a tuple\n",
    "#             # add tuple to an image-list\n",
    "    \n",
    "    \n",
    "# # LS to location information\n",
    "# # use the location info to find pixel values of other 8 cameras\n",
    "# # add them all into a tuple and in order of inputs to NN model, because they are input to our algorithm\n",
    "# # after calculating this for a block, we do prediction for the block.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77884b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da_latlon_list = []\n",
    "\n",
    "# for ii in range(512):\n",
    "#     for jj in range(2048):\n",
    "#         da = da_r_arr[ii,jj]\n",
    "#         if (da>=0):\n",
    "#             # also we need latlon for that pixel\n",
    "#             da_latlon = bls_to_latlon(path, resolution, block, ii, jj)\n",
    "#             da_lat = round(da_latlon[0], 4)\n",
    "#             da_lon = round(da_latlon[1], 4)\n",
    "# #             da_latlon_list.append(list(da_latlon + (da,)))\n",
    "#             da_latlon_list.append([da_lat, da_lon, round(da,6)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd48c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da_latlon_list\n",
    "# an_latlon_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa206c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now match an-latlon with da-latlon and find the da\n",
    "# for irow in da_latlon_list:\n",
    "# #     print(irow[0])\n",
    "#     if (irow[0]== an_latlon_list[0] and irow[1]== an_latlon_list[1]):\n",
    "#         da = irow[2]\n",
    "#         print('pixel found')\n",
    "#         print(da)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c402d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # align 9 images in a way that every pixel sits on each other\n",
    "# # how to remove the black sides of the imahes???????\n",
    "\n",
    "\n",
    "# type(da_r_arr)\n",
    "\n",
    "# # Create a mask to identify the desired values/region\n",
    "# mask = (da_r_arr >= 0)\n",
    "# # mask.shape\n",
    "\n",
    "# # Use boolean indexing to get the non -1 values\n",
    "# new_image = da_r_arr[mask]\n",
    "# new_image.shape\n",
    "\n",
    "# # # Reshape the 1D array back to a 2D array\n",
    "# # num_rows = 512\n",
    "# # num_cols = new_image.size // num_rows\n",
    "# # # num_cols\n",
    "# # new_image = new_image.reshape(num_rows, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60fc9a51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-17887b012637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# histogram and check available values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mret_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_image' is not defined"
     ]
    }
   ],
   "source": [
    "# visualize and check the cutted image\n",
    "# histogram and check available values\n",
    "\n",
    "ret_hist = plt.hist(new_image, bins='auto')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "893dc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loop and extract every pixel from all 9 cameras for each row & column, \n",
    "# # it should be based on the order of inputs/cameras to the model(important)\n",
    "\n",
    "# x_predict_block = []\n",
    "# fillvalue_index = []\n",
    "\n",
    "# for row in range(da_r_arr.shape[0]):\n",
    "#     for col in range(da_r_arr.shape[1]):\n",
    "\n",
    "#         # order of Xi should be based on the input orders to the our model\n",
    "#         # order: feature_columns = ['anr','aa','af','ba','bf','ca','cf','da','df']\n",
    "#         x1 = an_r_arr[row,col]\n",
    "#         x2 = aa_r_arr[row,col]\n",
    "#         x3 = af_r_arr[row,col]\n",
    "#         x4 = ba_r_arr[row,col]\n",
    "#         x5 = bf_r_arr[row,col]\n",
    "#         x6 = ca_r_arr[row,col]\n",
    "#         x7 = cf_r_arr[row,col]\n",
    "#         x8 = da_r_arr[row,col]\n",
    "#         x9 = df_r_arr[row,col]\n",
    "\n",
    "#         # check somewhere here if a pixel was == -1, then replace all pixels with fillvalue and continue to the next pixel\n",
    "\n",
    "        \n",
    "#         nine_features = [x1,x2,x3,x4,x5,x6,x7,x8,x9]\n",
    "#         # is -1 a good fillvalue for the edges?\n",
    "#         # if -1 in the list:\n",
    "#         # find the index, save the pixel index, and later replace w/fillvalue\n",
    "#         if -1.0 in nine_features:\n",
    "# #             print('-1 found in 9 features, save the index of this pixel.')\n",
    "#             fillvalue_index.append((row*2048)+col) # similar to C code for counting index numbers\n",
    "\n",
    "        \n",
    "#         #print(type(nine_features))\n",
    "#         x_predict_block.append(nine_features)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee9af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # apply the model and predict for a single block\n",
    "# ## prediction for each block\n",
    "\n",
    "# y_predict_block = mlp_model_best.predict(x_predict_block, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change class categories to one class\n",
    "\n",
    "# print(y_predict_block[100]) \n",
    "\n",
    "# # Set the threshold value to confirm classes\n",
    "# threshold = 0.5\n",
    "\n",
    "# # convert 1-hot prob to 1-hot encoding == binary classes\n",
    "# cloud_mask_one_hot = np.zeros_like(y_predict_block)\n",
    "# cloud_mask_one_hot[y_predict_block >= threshold] = 1\n",
    "# print(cloud_mask_one_hot)\n",
    "\n",
    "# # Convert 1-hot encoding to categorical 1-D output\n",
    "# cloudmask_categorical = np.zeros(cloud_mask_one_hot.shape[0]) # make a zero column\n",
    "# cloudmask_categorical[cloud_mask_one_hot[:, 1] == 1] = 1 # update the zero column==every pixel where it was originally 1\n",
    "# print(cloudmask_categorical)\n",
    "\n",
    "# # this is in 1-hot format? how to change it to normal format?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9716799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(cloudmask_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c488b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # update the the predicted categorical list with fillvalue using indexing and assignment\n",
    "# for i in fillvalue_index:\n",
    "# #     print(i)\n",
    "#     cloudmask_categorical[i] = -2 # -99 is fillvalue for a pixel in cloudmask that any camera was -1 in toa-refl==edges of image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df828be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloudmask_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change data type from float64 to int8\n",
    "# cloudmask_categorical = cloudmask_categorical.astype(np.int8)\n",
    "# cloudmask_categorical.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## re-construct cloudmask prediction list to 2D\n",
    "# print(cloudmask_categorical.shape) # shape is 2 because we have 2 classes\n",
    "# print(type(cloudmask_categorical))\n",
    "\n",
    "# cloudmask_categorical_2d = cloudmask_categorical.reshape((512,-1))\n",
    "# print(cloudmask_categorical_2d.dtype)\n",
    "# print('output cloumask shape: (%s, %s)' %(cloudmask_categorical_2d.shape))\n",
    "\n",
    "# print(\"min: %s\" %cloudmask_categorical_2d.min())\n",
    "# print(\"max: %s\" %cloudmask_categorical_2d.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1132c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # histogram of data in cloudmask\n",
    "\n",
    "# cloudmask_categorical_flat = cloudmask_categorical_2d.flatten()\n",
    "# print(cloudmask_categorical_flat.shape)\n",
    "\n",
    "# ret_hist = plt.hist(cloudmask_categorical_flat, bins='auto')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fece29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe visualize cloudmask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5824c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # p_o = 'P167_O088219'\n",
    "# # toa_block = '10'\n",
    "\n",
    "# out_raw_binary_label = 'cloudmask_'+POB+\".msk\"  # this image format supports saving neg- values in image\n",
    "# out_raw_binary_fullpath = os.path.join(output_dir, out_raw_binary_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a17411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## flatten array and save as binary raw file on local computer\n",
    "\n",
    "# cloudmask_categorical_2d.flatten().astype(np.int8).tofile(out_raw_binary_fullpath) # write as uint8 to be able to read by atmmodel.c\n",
    "# print(out_raw_binary_fullpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa495b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
